encoder:
  name: sentence-transformer-encoder
  params:
    model_name: bert-base-nli-mean-tokens
    data_split_number: 10
    dataset_dir: !ENV  ${JOBXMLC_DATA_DIR}/COLING
    embeddings_save_dir : !ENV ${JOBXMLC_DATA_DIR}/embeddings
  # data_filter:
  #   name: tf-idf
  #   params:
  #     number_of_words: 10
model:
  dataset_path:
  save_model: 0
  encoder: GIN
  num_epochs: 30
  num_HN_epochs: 20
  batch_size: 256
  lr: 0.0003
  attention_lr: 0.0003
  adjust_lr: 20,22,26
  dlr_factor: 0.5
  mpt: 0
  restrict_edges_num: -1
  restrict_edges_head_threshold: 3
  num_random_samples: 4
  random_shuffle_nbrs: 0
  fanouts: 5,5,5
  num_HN_shortlist: 20
  embedding_type: Stack-
  run_type: NR
  num_validation: -1
  validation_freq: -1
  num_shortlist: 275
  prediction_introduce_edges: 3
  predict_ova: 0
  A: 0.6
  B: 2.6
  name: New-FT-stack-jobs-all-no_sorting
  reporting:
  # console:
  #   module: baseline.reporting
  # wandb:
  #   module: eptests.core.reporting_wandb
